Files already downloaded and verified
Files already downloaded and verified
 2021-11-30 14:42:36,421 | INFO | root 	 classes_order
 2021-11-30 14:42:36,421 | INFO | root 	 [[87, 0, 52, 58, 44, 91, 68, 97, 51, 15, 94, 92, 10, 72, 49, 78, 61, 14, 8, 86, 84, 96, 18, 24, 32, 45, 88, 11, 4, 67, 69, 66, 77, 47, 79, 93, 29, 50, 57, 83, 17, 81, 41, 12, 37, 59, 25, 20, 80, 73, 1, 28, 6, 46, 62, 82, 53, 9, 31, 75, 38, 63, 33, 74, 27, 22, 36, 3, 16, 21, 60, 19, 70, 90, 89, 43, 5, 42, 65, 76, 40, 30, 23, 85, 2, 95, 56, 48, 71, 64, 98, 13, 99, 7, 34, 55, 54, 26, 35, 39]]
 2021-11-30 14:42:39,176 | INFO | root 	 Begin step 0
 2021-11-30 14:42:39,176 | INFO | root 	 Now [200, 200, 200, 200, 200, 200, 200, 200, 200, 200] examplars per class.
 2021-11-30 14:42:39,177 | INFO | root 	 Step 0 weight decay 0.00050
 2021-11-30 14:42:39,263 | INFO | root 	 Train on 0->10.
 2021-11-30 14:42:39,264 | INFO | root 	 nb 5000
 2021-11-30 14:42:39,265 | INFO | root 	 Initial trainset: Weight norm per class [1.007]
warmup
 2021-11-30 14:42:41,235 | INFO | root 	 Initial trainset: Feature norm per class [1.394]
 2021-11-30 14:42:43,657 | INFO | root 	 Task 1/10, Epoch 1/17 => Clf loss: 2.037 Aux loss: 0.0, Train Accu: 28.26
 2021-11-30 14:42:46,798 | INFO | root 	 Task 1/10, Epoch 2/17 => Clf loss: 1.783 Aux loss: 0.0, Train Accu: 37.38
 2021-11-30 14:42:49,872 | INFO | root 	 Task 1/10, Epoch 3/17 => Clf loss: 1.688 Aux loss: 0.0, Train Accu: 39.8
 2021-11-30 14:42:52,976 | INFO | root 	 Task 1/10, Epoch 4/17 => Clf loss: 1.636 Aux loss: 0.0, Train Accu: 42.26
 2021-11-30 14:42:56,119 | INFO | root 	 Task 1/10, Epoch 5/17 => Clf loss: 1.525 Aux loss: 0.0, Train Accu: 46.56
 2021-11-30 14:42:59,247 | INFO | root 	 Task 1/10, Epoch 6/17 => Clf loss: 1.465 Aux loss: 0.0, Train Accu: 49.02
 2021-11-30 14:43:02,366 | INFO | root 	 Task 1/10, Epoch 7/17 => Clf loss: 1.406 Aux loss: 0.0, Train Accu: 51.38
 2021-11-30 14:43:05,473 | INFO | root 	 Task 1/10, Epoch 8/17 => Clf loss: 1.331 Aux loss: 0.0, Train Accu: 55.04
 2021-11-30 14:43:08,605 | INFO | root 	 Task 1/10, Epoch 9/17 => Clf loss: 1.179 Aux loss: 0.0, Train Accu: 59.9
 2021-11-30 14:43:11,725 | INFO | root 	 Task 1/10, Epoch 10/17 => Clf loss: 1.113 Aux loss: 0.0, Train Accu: 61.36
 2021-11-30 14:43:14,803 | INFO | root 	 Task 1/10, Epoch 11/17 => Clf loss: 1.26 Aux loss: 0.0, Train Accu: 56.58
 2021-11-30 14:43:17,902 | INFO | root 	 Task 1/10, Epoch 12/17 => Clf loss: 0.995 Aux loss: 0.0, Train Accu: 66.08
 2021-11-30 14:43:21,049 | INFO | root 	 Task 1/10, Epoch 13/17 => Clf loss: 0.912 Aux loss: 0.0, Train Accu: 68.26
 2021-11-30 14:43:24,134 | INFO | root 	 Task 1/10, Epoch 14/17 => Clf loss: 0.932 Aux loss: 0.0, Train Accu: 67.68
 2021-11-30 14:43:27,258 | INFO | root 	 Task 1/10, Epoch 15/17 => Clf loss: 0.803 Aux loss: 0.0, Train Accu: 71.6
 2021-11-30 14:43:30,349 | INFO | root 	 Task 1/10, Epoch 16/17 => Clf loss: 0.711 Aux loss: 0.0, Train Accu: 76.96
 2021-11-30 14:43:33,462 | INFO | root 	 Task 1/10, Epoch 17/17 => Clf loss: 0.812 Aux loss: 0.0, Train Accu: 72.92
 2021-11-30 14:43:34,129 | INFO | root 	 After training: Weight norm per class [2.314]
 2021-11-30 14:43:35,372 | INFO | root 	 Trainset: Feature norm per class [5.462]
 2021-11-30 14:43:36,121 | INFO | root 	 build memory
 2021-11-30 14:43:36,122 | INFO | root 	 Building & updating memory.(iCaRL)
ema init
 2021-11-30 14:43:44,073 | INFO | root 	 Save step0 memory!
 2021-11-30 14:43:44,074 | INFO | root 	 Eval on 0->10.
 2021-11-30 14:43:44,749 | INFO | root 	 top1:{'total': 71.6, '00-09': 71.6}
 2021-11-30 14:43:44,749 | INFO | root 	 top1 ema:{'total': 71.6, '00-09': 71.6}
 2021-11-30 14:43:44,749 | INFO | root 	 top5:{'total': 97.7, '00-09': 97.7}
 2021-11-30 14:43:44,749 | INFO | root 	 top5 ema:{'total': 97.7, '00-09': 97.7}
 2021-11-30 14:43:45,067 | INFO | root 	 Begin step 1
 2021-11-30 14:43:45,067 | INFO | root 	 Now [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100] examplars per class.
 2021-11-30 14:43:45,069 | INFO | root 	 Step 1 weight decay 0.00050
 2021-11-30 14:43:45,158 | INFO | root 	 Train on 10->20.
 2021-11-30 14:43:45,159 | INFO | root 	 nb 7000
 2021-11-30 14:43:45,160 | INFO | root 	 Initial trainset: Weight norm per class [1.009, 0.998]
Set memory of size: 2000.
warmup
 2021-11-30 14:43:46,600 | INFO | root 	 Initial trainset: Feature norm per class [5.419, 4.948]
/home/share/jiawei/anaconda3/envs/torch3090/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/conda/conda-bld/pytorch_1631630836880/work/aten/src/ATen/native/BinaryOps.cpp:467.)
  return torch.floor_divide(self, other)
> /home/share/jiawei/solf/inclearn/convnet/MetaModules.py(260)forward()
-> return F.conv2d(x, self.weight, self.bias, self.stride, self.padding, self.dilation, self.groups)
[?2004h(Pdb)
Traceback (most recent call last):
  File "/home/share/jiawei/anaconda3/envs/torch3090/lib/python3.7/site-packages/sacred/experiment.py", line 318, in run_commandline
    options=args,
  File "/home/share/jiawei/anaconda3/envs/torch3090/lib/python3.7/site-packages/sacred/experiment.py", line 276, in run
    run()
  File "/home/share/jiawei/anaconda3/envs/torch3090/lib/python3.7/site-packages/sacred/run.py", line 238, in __call__
    self.result = self.main_function(*args)
  File "/home/share/jiawei/anaconda3/envs/torch3090/lib/python3.7/site-packages/sacred/config/captured_function.py", line 42, in captured_function
    result = wrapped(*args, **kwargs)
  File "/home/share/jiawei/solf/codes/base/main.py", line 69, in train
    _train(cfg, _run, ex, tensorboard)
  File "/home/share/jiawei/solf/codes/base/main.py", line 120, in _train
    model.train_task(train_loader, val_loader)
  File "/home/share/jiawei/solf/inclearn/models/base.py", line 43, in train_task
    self._train_task(train_loader, val_loader)
  File "/home/share/jiawei/solf/inclearn/models/incmodel.py", line 315, in _train_task
    self._get_ttrans()
  File "/home/share/jiawei/solf/inclearn/models/incmodel.py", line 461, in _get_ttrans
    Z_o = torch.cat((self.ema_network(X)['feature'].detach(),torch.ones((X.shape[0],1),dtype=torch.float32, device=self._device)),1)
  File "/home/share/jiawei/anaconda3/envs/torch3090/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/share/jiawei/solf/inclearn/convnet/network.py", line 90, in forward
    features = self.convnet(x)
  File "/home/share/jiawei/anaconda3/envs/torch3090/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/share/jiawei/solf/inclearn/convnet/resMeta.py", line 171, in forward
    x = self.conv1(x)
  File "/home/share/jiawei/anaconda3/envs/torch3090/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/share/jiawei/solf/inclearn/convnet/MetaModules.py", line 260, in forward
    return F.conv2d(x, self.weight, self.bias, self.stride, self.padding, self.dilation, self.groups)
[?2004h(Pdb) [?2004l
