Files already downloaded and verified
Files already downloaded and verified
 2021-11-30 18:42:00,150 | INFO | root 	 classes_order
 2021-11-30 18:42:00,150 | INFO | root 	 [[87, 0, 52, 58, 44, 91, 68, 97, 51, 15, 94, 92, 10, 72, 49, 78, 61, 14, 8, 86, 84, 96, 18, 24, 32, 45, 88, 11, 4, 67, 69, 66, 77, 47, 79, 93, 29, 50, 57, 83, 17, 81, 41, 12, 37, 59, 25, 20, 80, 73, 1, 28, 6, 46, 62, 82, 53, 9, 31, 75, 38, 63, 33, 74, 27, 22, 36, 3, 16, 21, 60, 19, 70, 90, 89, 43, 5, 42, 65, 76, 40, 30, 23, 85, 2, 95, 56, 48, 71, 64, 98, 13, 99, 7, 34, 55, 54, 26, 35, 39]]
 2021-11-30 18:42:02,973 | INFO | root 	 Begin step 0
 2021-11-30 18:42:02,973 | INFO | root 	 Now [200, 200, 200, 200, 200, 200, 200, 200, 200, 200] examplars per class.
 2021-11-30 18:42:02,975 | INFO | root 	 Step 0 weight decay 0.00050
 2021-11-30 18:42:03,061 | INFO | root 	 Train on 0->10.
 2021-11-30 18:42:03,062 | INFO | root 	 nb 5000
 2021-11-30 18:42:03,063 | INFO | root 	 Initial trainset: Weight norm per class [1.007]
warmup
 2021-11-30 18:42:05,016 | INFO | root 	 Initial trainset: Feature norm per class [1.394]
 2021-11-30 18:42:07,556 | INFO | root 	 Task 1/10, Epoch 1/17 => Clf loss: 2.037 Aux loss: 0.0, Train Accu: 28.26
 2021-11-30 18:42:10,798 | INFO | root 	 Task 1/10, Epoch 2/17 => Clf loss: 1.783 Aux loss: 0.0, Train Accu: 37.38
 2021-11-30 18:42:14,054 | INFO | root 	 Task 1/10, Epoch 3/17 => Clf loss: 1.688 Aux loss: 0.0, Train Accu: 39.8
 2021-11-30 18:42:17,291 | INFO | root 	 Task 1/10, Epoch 4/17 => Clf loss: 1.636 Aux loss: 0.0, Train Accu: 42.26
 2021-11-30 18:42:20,565 | INFO | root 	 Task 1/10, Epoch 5/17 => Clf loss: 1.525 Aux loss: 0.0, Train Accu: 46.56
 2021-11-30 18:42:23,746 | INFO | root 	 Task 1/10, Epoch 6/17 => Clf loss: 1.465 Aux loss: 0.0, Train Accu: 49.02
 2021-11-30 18:42:27,021 | INFO | root 	 Task 1/10, Epoch 7/17 => Clf loss: 1.406 Aux loss: 0.0, Train Accu: 51.38
 2021-11-30 18:42:30,278 | INFO | root 	 Task 1/10, Epoch 8/17 => Clf loss: 1.331 Aux loss: 0.0, Train Accu: 55.04
 2021-11-30 18:42:33,588 | INFO | root 	 Task 1/10, Epoch 9/17 => Clf loss: 1.179 Aux loss: 0.0, Train Accu: 59.9
 2021-11-30 18:42:36,842 | INFO | root 	 Task 1/10, Epoch 10/17 => Clf loss: 1.113 Aux loss: 0.0, Train Accu: 61.36
 2021-11-30 18:42:40,110 | INFO | root 	 Task 1/10, Epoch 11/17 => Clf loss: 1.26 Aux loss: 0.0, Train Accu: 56.58
 2021-11-30 18:42:43,316 | INFO | root 	 Task 1/10, Epoch 12/17 => Clf loss: 0.995 Aux loss: 0.0, Train Accu: 66.08
 2021-11-30 18:42:46,562 | INFO | root 	 Task 1/10, Epoch 13/17 => Clf loss: 0.912 Aux loss: 0.0, Train Accu: 68.26
 2021-11-30 18:42:49,891 | INFO | root 	 Task 1/10, Epoch 14/17 => Clf loss: 0.932 Aux loss: 0.0, Train Accu: 67.68
 2021-11-30 18:42:53,162 | INFO | root 	 Task 1/10, Epoch 15/17 => Clf loss: 0.803 Aux loss: 0.0, Train Accu: 71.6
 2021-11-30 18:42:56,434 | INFO | root 	 Task 1/10, Epoch 16/17 => Clf loss: 0.711 Aux loss: 0.0, Train Accu: 76.96
 2021-11-30 18:42:59,618 | INFO | root 	 Task 1/10, Epoch 17/17 => Clf loss: 0.812 Aux loss: 0.0, Train Accu: 72.92
ema init
 2021-11-30 18:43:00,357 | INFO | root 	 After training: Weight norm per class [2.314]
 2021-11-30 18:43:01,684 | INFO | root 	 Trainset: Feature norm per class [5.462]
 2021-11-30 18:43:03,596 | INFO | root 	 build memory
 2021-11-30 18:43:03,597 | INFO | root 	 Building & updating memory.(iCaRL)
Set memory of size: 2000.
warmup
 2021-11-30 18:43:12,318 | INFO | root 	 Save step0 memory!
 2021-11-30 18:43:12,319 | INFO | root 	 Eval on 0->10.
 2021-11-30 18:43:13,053 | INFO | root 	 top1:{'total': 71.6, '00-09': 71.6}
 2021-11-30 18:43:13,053 | INFO | root 	 top1 ema:{'total': 71.6, '00-09': 71.6}
 2021-11-30 18:43:13,053 | INFO | root 	 top5:{'total': 97.7, '00-09': 97.7}
 2021-11-30 18:43:13,053 | INFO | root 	 top5 ema:{'total': 97.7, '00-09': 97.7}
 2021-11-30 18:43:13,406 | INFO | root 	 Begin step 1
 2021-11-30 18:43:13,406 | INFO | root 	 Now [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100] examplars per class.
 2021-11-30 18:43:13,408 | INFO | root 	 Step 1 weight decay 0.00050
 2021-11-30 18:43:13,497 | INFO | root 	 Train on 10->20.
 2021-11-30 18:43:13,498 | INFO | root 	 nb 7000
 2021-11-30 18:43:13,499 | INFO | root 	 Initial trainset: Weight norm per class [1.009, 0.998]
 2021-11-30 18:43:14,976 | INFO | root 	 Initial trainset: Feature norm per class [5.419, 4.948]
/home/share/jiawei/anaconda3/envs/torch3090/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/conda/conda-bld/pytorch_1631630836880/work/aten/src/ATen/native/BinaryOps.cpp:467.)
  return torch.floor_divide(self, other)
 2021-11-30 18:43:20,732 | INFO | root 	 Task 2/10, Epoch 1/17 => Clf loss: 2.996 Aux loss: 0.508, Train Accu: 26.571
 2021-11-30 18:43:26,761 | INFO | root 	 Task 2/10, Epoch 2/17 => Clf loss: 2.213 Aux loss: 0.462, Train Accu: 42.771
 2021-11-30 18:43:32,834 | INFO | root 	 Task 2/10, Epoch 3/17 => Clf loss: 1.931 Aux loss: 0.408, Train Accu: 48.871
 2021-11-30 18:43:38,926 | INFO | root 	 Task 2/10, Epoch 4/17 => Clf loss: 1.788 Aux loss: 0.344, Train Accu: 52.229
 2021-11-30 18:43:45,013 | INFO | root 	 Task 2/10, Epoch 5/17 => Clf loss: 1.702 Aux loss: 0.287, Train Accu: 56.6
 2021-11-30 18:43:51,059 | INFO | root 	 Task 2/10, Epoch 6/17 => Clf loss: 1.638 Aux loss: 0.246, Train Accu: 59.371
 2021-11-30 18:43:57,045 | INFO | root 	 Task 2/10, Epoch 7/17 => Clf loss: 1.599 Aux loss: 0.214, Train Accu: 60.9
 2021-11-30 18:44:03,073 | INFO | root 	 Task 2/10, Epoch 8/17 => Clf loss: 1.556 Aux loss: 0.193, Train Accu: 62.886
 2021-11-30 18:44:09,090 | INFO | root 	 Task 2/10, Epoch 9/17 => Clf loss: 1.519 Aux loss: 0.176, Train Accu: 65.743
 2021-11-30 18:44:15,154 | INFO | root 	 Task 2/10, Epoch 10/17 => Clf loss: 1.497 Aux loss: 0.161, Train Accu: 66.143
 2021-11-30 18:44:21,256 | INFO | root 	 Task 2/10, Epoch 11/17 => Clf loss: 1.998 Aux loss: 0.205, Train Accu: 58.586
 2021-11-30 18:44:27,259 | INFO | root 	 Task 2/10, Epoch 12/17 => Clf loss: 1.501 Aux loss: 0.184, Train Accu: 67.8
 2021-11-30 18:44:33,340 | INFO | root 	 Task 2/10, Epoch 13/17 => Clf loss: 1.442 Aux loss: 0.156, Train Accu: 70.343
 2021-11-30 18:44:39,395 | INFO | root 	 Task 2/10, Epoch 14/17 => Clf loss: 1.391 Aux loss: 0.141, Train Accu: 72.057
 2021-11-30 18:44:45,458 | INFO | root 	 Task 2/10, Epoch 15/17 => Clf loss: 1.359 Aux loss: 0.132, Train Accu: 73.143
 2021-11-30 18:44:51,516 | INFO | root 	 Task 2/10, Epoch 16/17 => Clf loss: 1.35 Aux loss: 0.121, Train Accu: 73.857
 2021-11-30 18:44:57,648 | INFO | root 	 Task 2/10, Epoch 17/17 => Clf loss: 1.315 Aux loss: 0.117, Train Accu: 75.6
 2021-11-30 18:44:58,552 | INFO | root 	 After training: Weight norm per class [2.817, 2.699]
ema init
 2021-11-30 18:45:00,001 | INFO | root 	 Trainset: Feature norm per class [3.365, 2.539]
 2021-11-30 18:45:02,114 | INFO | root 	 Begin finetuning last layer
 2021-11-30 18:45:04,944 | INFO | root 	 Epoch 0 finetuning loss 2.949 acc 0.305
 2021-11-30 18:45:07,803 | INFO | root 	 Epoch 1 finetuning loss 2.816 acc 0.619
 2021-11-30 18:45:10,622 | INFO | root 	 Epoch 2 finetuning loss 2.685 acc 0.650
 2021-11-30 18:45:13,497 | INFO | root 	 Epoch 3 finetuning loss 2.568 acc 0.648
 2021-11-30 18:45:16,321 | INFO | root 	 Epoch 4 finetuning loss 2.463 acc 0.654
 2021-11-30 18:45:19,171 | INFO | root 	 Epoch 5 finetuning loss 2.368 acc 0.662
 2021-11-30 18:45:22,031 | INFO | root 	 Epoch 6 finetuning loss 2.288 acc 0.669
 2021-11-30 18:45:24,913 | INFO | root 	 Epoch 7 finetuning loss 2.216 acc 0.684
 2021-11-30 18:45:27,774 | INFO | root 	 Epoch 8 finetuning loss 2.149 acc 0.685
 2021-11-30 18:45:30,586 | INFO | root 	 Epoch 9 finetuning loss 2.086 acc 0.692
 2021-11-30 18:45:33,483 | INFO | root 	 Epoch 10 finetuning loss 2.033 acc 0.700
 2021-11-30 18:45:36,328 | INFO | root 	 Epoch 11 finetuning loss 1.986 acc 0.693
 2021-11-30 18:45:39,174 | INFO | root 	 Epoch 12 finetuning loss 1.937 acc 0.703
 2021-11-30 18:45:42,034 | INFO | root 	 Epoch 13 finetuning loss 1.893 acc 0.712
 2021-11-30 18:45:44,873 | INFO | root 	 Epoch 14 finetuning loss 1.852 acc 0.720
 2021-11-30 18:45:47,801 | INFO | root 	 Epoch 15 finetuning loss 1.827 acc 0.720
 2021-11-30 18:45:50,818 | INFO | root 	 Epoch 16 finetuning loss 1.826 acc 0.715
 2021-11-30 18:45:53,666 | INFO | root 	 Epoch 17 finetuning loss 1.821 acc 0.714
 2021-11-30 18:45:56,488 | INFO | root 	 Epoch 18 finetuning loss 1.817 acc 0.719
 2021-11-30 18:45:59,327 | INFO | root 	 Epoch 19 finetuning loss 1.814 acc 0.718
 2021-11-30 18:46:02,158 | INFO | root 	 Epoch 20 finetuning loss 1.812 acc 0.721
 2021-11-30 18:46:04,969 | INFO | root 	 Epoch 21 finetuning loss 1.804 acc 0.726
 2021-11-30 18:46:07,802 | INFO | root 	 Epoch 22 finetuning loss 1.801 acc 0.715
 2021-11-30 18:46:10,643 | INFO | root 	 Epoch 23 finetuning loss 1.797 acc 0.724
 2021-11-30 18:46:13,476 | INFO | root 	 Epoch 24 finetuning loss 1.795 acc 0.720
 2021-11-30 18:46:16,307 | INFO | root 	 Epoch 25 finetuning loss 1.797 acc 0.721
 2021-11-30 18:46:19,156 | INFO | root 	 Epoch 26 finetuning loss 1.787 acc 0.720
 2021-11-30 18:46:21,997 | INFO | root 	 Epoch 27 finetuning loss 1.785 acc 0.722
 2021-11-30 18:46:24,859 | INFO | root 	 Epoch 28 finetuning loss 1.782 acc 0.721
 2021-11-30 18:46:27,690 | INFO | root 	 Epoch 29 finetuning loss 1.776 acc 0.721
 2021-11-30 18:46:30,523 | INFO | root 	 Epoch 30 finetuning loss 1.776 acc 0.724
 2021-11-30 18:46:33,353 | INFO | root 	 Epoch 31 finetuning loss 1.778 acc 0.717
 2021-11-30 18:46:36,190 | INFO | root 	 Epoch 32 finetuning loss 1.779 acc 0.724
 2021-11-30 18:46:39,020 | INFO | root 	 Epoch 33 finetuning loss 1.770 acc 0.729
 2021-11-30 18:46:41,845 | INFO | root 	 Epoch 34 finetuning loss 1.779 acc 0.722
 2021-11-30 18:46:44,707 | INFO | root 	 Epoch 35 finetuning loss 1.777 acc 0.725
 2021-11-30 18:46:47,577 | INFO | root 	 Epoch 36 finetuning loss 1.771 acc 0.728
 2021-11-30 18:46:50,402 | INFO | root 	 Epoch 37 finetuning loss 1.776 acc 0.719
 2021-11-30 18:46:53,259 | INFO | root 	 Epoch 38 finetuning loss 1.770 acc 0.720
 2021-11-30 18:46:56,112 | INFO | root 	 Epoch 39 finetuning loss 1.778 acc 0.720
 2021-11-30 18:46:58,932 | INFO | root 	 Epoch 40 finetuning loss 1.769 acc 0.720
 2021-11-30 18:47:01,779 | INFO | root 	 Epoch 41 finetuning loss 1.775 acc 0.727
 2021-11-30 18:47:04,604 | INFO | root 	 Epoch 42 finetuning loss 1.774 acc 0.727
 2021-11-30 18:47:07,450 | INFO | root 	 Epoch 43 finetuning loss 1.772 acc 0.724
